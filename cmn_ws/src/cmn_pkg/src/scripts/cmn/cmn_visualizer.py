#!/usr/bin/env python3

from matplotlib.backends.backend_agg import FigureCanvasAgg
from matplotlib.figure import Figure
from matplotlib.gridspec import GridSpec
import cv2
import numpy as np

from scripts.basic_types import PosePixels

class CoarseMapNavVisualizer:
    """
    Functions to visualize discrete CMN data during the run.
    """
    # Sensor data & observations.
    pano_rgb:np.ndarray = None # Current panoramic RGB measurement that was used to generate the current local map.
    # Local maps are all 128x128 binary numpy arrays, with 1=free, 0=occ.
    current_predicted_local_map:np.ndarray = None # Current observation generated by the ML model.
    current_ground_truth_local_map:np.ndarray = None # Current observation generated by the simulator (if enabled). 3x3 upscaled to 128x128.
    gt_is_depth:bool = False # Flag to change title of GT plot if it's from depth.
    lidar_local_occ_meas:np.ndarray = None # Data from spoofing a local occupancy measurement from LiDAR.
    # Beliefs.
    predictive_belief_map:np.ndarray = None # Prediction update step.
    observation_prob_map:np.ndarray = None # Measurement update step.
    agent_belief_map:np.ndarray = None # Combined updated belief.
    # Data for showing current localization and path planning.
    coarse_map:np.ndarray = None
    current_localization_estimate:PosePixels = None
    goal_cell:PosePixels = None
    planned_path_to_goal = None
    # True orientation, if we're assuming it's known, is just printed to more easily interpret the viz.
    robot_direction:str = None # Cardinal direction the robot is facing, if it's known.


    def __init__(self):
        """
        Initialize the CMN Visualizer.
        """
        pass

    @staticmethod
    def normalize_belief_for_visualization(belief):
        """
        @param belief - 2D numpy array of floats.
        """
        v_min = belief.min()
        v_max = belief.max()
        belief = (belief - v_min) / (v_max - v_min + 1e-8)
        return np.clip(belief, a_min=0, a_max=1)


    def get_updated_img(self):
        """
        Update the plot with all the most recent data, and redraw the viz.
        @ref https://stackoverflow.com/a/62040123/14783583
        @return new viz image as a cv/numpy matrix.
        """
        # Make a Figure and attach it to a canvas.
        fig = Figure(figsize=(8, 6), dpi=100)
        canvas = FigureCanvasAgg(fig)
        grid = GridSpec(3, 3, figure=fig)

        # Add subplots for observations and local occupancy GT / Pred
        ax_pano_rgb = fig.add_subplot(grid[0, :])
        ax_local_occ_gt = fig.add_subplot(grid[1, 0])
        ax_local_occ_pred = fig.add_subplot(grid[1, 1])
        ax_lidar_local_occ = fig.add_subplot(grid[1, 2])
        # Add subplots for beliefs
        ax_coarse_map = fig.add_subplot(grid[2, 0])
        # ax_pred_update_bel = fig.add_subplot(grid[2, 0])
        ax_obs_update_bel = fig.add_subplot(grid[2, 1])
        ax_belief = fig.add_subplot(grid[2, 2])

        # Set titles and remove axis
        ax_pano_rgb.set_title("Panoramic RGB observation" + " (facing {:})".format(self.robot_direction) if self.robot_direction is not None else "")
        ax_pano_rgb.axis("off")
        ax_local_occ_gt.set_title("GT local occ" if not self.gt_is_depth else "Depth local occ")
        ax_local_occ_gt.axis("off")
        ax_local_occ_pred.set_title("Pred local occ")
        ax_local_occ_pred.axis("off")
        ax_lidar_local_occ.set_title("LiDAR local occ")
        ax_lidar_local_occ.axis("off")
        ax_coarse_map.set_title("Coarse Map")
        ax_coarse_map.axis("off")
        # ax_pred_update_bel.set_title("Predictive belief")
        # ax_pred_update_bel.axis("off")
        ax_obs_update_bel.set_title("Obs belief")
        ax_obs_update_bel.axis("off")
        ax_belief.set_title("Belief")
        ax_belief.axis("off")

        # Add data to all plots.
        if self.pano_rgb is not None:
            ax_pano_rgb.imshow(cv2.cvtColor(self.pano_rgb, cv2.COLOR_RGB2BGR))

        if self.current_ground_truth_local_map is not None:
            ax_local_occ_gt.imshow(self.current_ground_truth_local_map.astype('float'), cmap="gray", vmin=0, vmax=1)
            
        if self.current_predicted_local_map is not None:
            ax_local_occ_pred.imshow(self.current_predicted_local_map.astype('float'), cmap="gray", vmin=0, vmax=1)

        if self.lidar_local_occ_meas is not None:
            ax_lidar_local_occ.imshow(self.lidar_local_occ_meas.astype('float'), cmap="gray", vmin=0, vmax=1)

        # if self.predictive_belief_map is not None:
        #     predictive_belief = self.normalize_belief_for_visualization(self.predictive_belief_map)
        #     ax_pred_update_bel.imshow(predictive_belief.astype('float'), cmap="gray", vmin=0, vmax=1)

        if self.observation_prob_map is not None:
            belief = self.normalize_belief_for_visualization(self.observation_prob_map)
            # If the filter is estimating yaw as well as position, this will be 4 layers instead of 1.
            if len(belief.shape) > 2 and belief.shape[2] == 4:
                belief_grid = np.zeros((belief.shape[0]*2, belief.shape[1]*2), dtype=float)
                belief_grid[:belief.shape[0], :belief.shape[1]] = belief[:,:,0]
                belief_grid[:belief.shape[0], belief.shape[1]:] = belief[:,:,1]
                belief_grid[belief.shape[0]:, :belief.shape[1]] = belief[:,:,2]
                belief_grid[belief.shape[0]:, belief.shape[1]:] = belief[:,:,3]
                ax_obs_update_bel.imshow(belief_grid.astype('float'), cmap="gray", vmin=0, vmax=1)
            else:
                ax_obs_update_bel.imshow(belief.astype('float'), cmap="gray", vmin=0, vmax=1)

        if self.agent_belief_map is not None:
            belief = self.normalize_belief_for_visualization(self.agent_belief_map)
            # If the filter is estimating yaw as well as position, this will be 4 layers instead of 1.
            if len(belief.shape) > 2 and belief.shape[2] == 4:
                belief_grid = np.zeros((belief.shape[0]*2, belief.shape[1]*2), dtype=float)
                belief_grid[:belief.shape[0], :belief.shape[1]] = belief[:,:,0]
                belief_grid[:belief.shape[0], belief.shape[1]:] = belief[:,:,1]
                belief_grid[belief.shape[0]:, :belief.shape[1]] = belief[:,:,2]
                belief_grid[belief.shape[0]:, belief.shape[1]:] = belief[:,:,3]
                ax_belief.imshow(belief_grid.astype('float'), cmap="gray", vmin=0, vmax=1)
            else:
                ax_belief.imshow(belief.astype('float'), cmap="gray", vmin=0, vmax=1)

        if self.coarse_map is not None:
            # Convert coarse map to BGR.
            # img = cv2.cvtColor(self.coarse_map.copy(), cv2.COLOR_GRAY2BGR)
            map_img = (self.coarse_map.copy() * 255).astype('uint8')
            img = np.zeros((map_img.shape[0], map_img.shape[1], 3), dtype="uint8")
            img[:,:,0] = map_img
            img[:,:,1] = map_img
            img[:,:,2] = map_img
            # Show other data on top of the coarse map.
            if self.planned_path_to_goal is not None:
                for cell in self.planned_path_to_goal:
                    img = cv2.circle(img, [cell.c, cell.r], 0, (255,0,255), -1)
            if self.current_localization_estimate is not None:
                # Show cell for current localization estimate.
                img = cv2.circle(img, [self.current_localization_estimate.c, self.current_localization_estimate.r], 0, (0,255,0), -1)
            if self.goal_cell is not None:
                # Show cell for current goal.
                img = cv2.circle(img, [self.goal_cell.c, self.goal_cell.r], 0, (255,255,0), -1)
            # Add this to the viz.
            ax_coarse_map.imshow(img)


        # Retrieve a view on the renderer buffer
        canvas.draw()
        buf = canvas.buffer_rgba()
        # convert to a NumPy array
        result_img = np.asarray(buf)
        # Convert to the correct color scheme.
        return cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
    