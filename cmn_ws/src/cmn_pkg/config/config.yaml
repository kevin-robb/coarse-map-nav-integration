# Parameters for the project

verbose: false # Show a lot more debug information.

# Rate at which to publish velocity commands to the robot.
dt: 0.1 # timer period in seconds.

# Flag to enable collection of training data for the model. Requires the coarse map be set to a high-fidelity map (i.e., from cartographer in the same environment).
# Save measurements, true odom pose on map, and "observation" pulled from the map, all with timestamps & frame numbers to associate them. This data can be used to retrain the ML model, and also allows re-running the project to evaluate the model & localization to compare to ground truth. May also need to save commands or relative motions depending on how the localization is implemented. NOTE could use rosbags for the replaying aspect, but for training the model we still need a way to get associated measurements + "observations".
save_data_for_training: false

# Details about the measurements that will be used to generate observations.
measurements:
  topic: "/locobot/camera/color/image_raw" # Rostopic the robot will be publishing images to.
  height: 224 # Images will be resized to this height (in px) before being given to the model.
  width: 224 # Images will be resized to this width (in px) before being given to the model.
  use_panorama: True # If true, the robot will do a 360 degree in-place pivot to collect an image from each cardinal direction and construct a panoramic image for every iteration.

# Details about the coarse map.
map:
  # fname: "building1.png" # Name of the map image file to use. Image should be in cmn_pkg/config/maps/ directory.
  fname: "Eudora_map_binary_arr_mpp_03.npy" # Name of the map image file to use. Image should be in cmn_pkg/config/maps/ directory.
  desired_meters_per_pixel: 0.05 # Image will be resized to fit this desired granularity.
  obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.
  show_images_during_pre_proc: false # If true, display map at each stage of pre-processing.

# Config params defining how the observation output from the perception model relates to the robot.
# These should be known, since they are determined by the observation "ground truth" outputs used to train the model in the first place.
observation:
  resolution: 0.03 # Image resolution, in meters/pixel.
  height: 5 # in pixels. forward distance ahead of vehicle.
  width: 5 # in pixels. lateral span.
  # Coordinates on the observation image frame the vehicle's POV is.
  veh_horz_pos_ratio: 0.5 # relative position from left (0) to right (1). Use 0.5 to center it.
  veh_vert_pos_ratio: 0.0 # relative position from bottom (0) to top (1). Use 0.5 to center it.

particle_filter:
  enable: false # For debugging, localization can be disabled entirely with this flag.
  num_particles: 10 # Number of particles to track.
  state_size: 3 # Number of variables in the state. (i.e., (x,y,yaw)).
  random_sampling_rate: 0.1 # Proportion in range [0, 1] of population that will be sampled randomly instead of from the previous generation.

actions:
  discrete_forward_dist: 0.15 # meters forward to move for discrete motion action.
  discrete_forward_skip_probability: 0.1 # probability that a forward action will be skipped instead of commanded to the robot.

path_planning:
  do_path_planning: false # if true, use A* to compute a full path to the goal point, then use pure pursuit to choose a motion command. if false, navigate directly towards goal point.

# Configs for running simulator node for basic testing.
simulator:
  # ground_truth_map:
  #   use_diff_map_than_coarse_map: false # if true, use the following params to setup the ground truth map. If false, the coarse map will be used.
  #   fname: "igvc1.png" # Name of the map image file to use. Image should be in cmn_pkg/config/maps/ directory.
  #   obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.
  ground_truth_pose:
    veh_x_initial: 0.0 # meters from left.
    veh_y_initial: 0.0 # meters from bottom.
    veh_yaw_initial: 0.0 # radians. 0 = facing right, increases CCW.
  allow_motion_through_occupied_cells: true # if true, robot is allowed to be in occluded cells.

constraints:
  fwd: 0.6 # commanded linear velocity must be between 0 and this amount (meters/sec).
  ang: 1 # commanded angular velocity has its magnitude limited by this amount (radians/sec).

# Goal is reached when these minimum deviations are satisfied.
goal_reach_deviation:
  linear: 0.1 # meters.
  angular: 1.0 # degrees.

# Configs from the original CMN demo.
cmn:
  device: "cuda:0"
  scene_dir: "./Env/scene_file"
  scene_name: "Eudora"
  episode_num: 10
  visualize_freq: 30
  local_occ_net:
      dropout: 0.5
      use_pretrained_resnet18: True
  environment:
      scene_cfg:
          scene_file: ""
          random_seed: 1234
          allow_sliding: True
          max_episode_length: 500
          goal_reach_eps: 0.5
      sensor_cfg:
          use_sensors: ["color_sensor"]
          sensor_height: 0.6
          obs_width: 224
          obs_height: 224
          enable_panorama: True
          clip_depth_max: 0.0
          enable_noisy_observation: False
          noise_intensity: 0.1
      map_cfg:
          top_down_type: "boundary"
          meters_per_pixel: 0.01
          local_map_size: 64
          enable_local_map: True
          enable_ego_local_map: True
          show_agent: True
          show_goal: True
      agent_cfg:
          move_forward: 0.15
          turn_left: 90
          turn_right: 90
          enable_noisy_actuation: False
  cmn_cfg:
      mpp: "03"
      local_map_size: 3
      forward_step_k: 2
      forward_meter: 0.1
