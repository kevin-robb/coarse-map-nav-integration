# Parameters for the project

# Rate at which to publish commands to the robot.
dt: 0.1 # timer period in seconds.

# Rostopics used throughout the project.
topics:
  measurements: "/locobot/camera/color/image_raw"
  observations: "/observation"
  occ_map: "/map/occ"
  raw_map: "/map/raw"
  localization: "/state_est"
  goal: "/goal"
  commands: "/locobot/mobile_base/commands/velocity"
  planned_path: "/planned_path"

# Details about the coarse map.
map:
  fname: "building2.png" # Name of the map image file to use. Image should be in cmn_pkg/config/maps/ directory.
  downscale_ratio: 0.2 # Resize map to lower resolution. This helps A* to run faster. New side lengths will be original*downscale_ratio.
  resolution: 0.01 # Assumed map resolution, in meters/pixel. This will later be estimated as part of the filter to allow a map with unknown scale to be used.
  occ_thresh: 200 # Integer in range [0,255]. All cells with grayscale value < this will be considered occupied.
  obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.

# Config params defining how the observation output from the perception model relates to the robot.
# These should be known, since they are determined by the observation "ground truth" outputs used to train the model in the first place.
observation:
  resolution: 0.03 # Image resolution, in meters/pixel.
  height: 5 # in pixels. forward distance ahead of vehicle.
  width: 5 # in pixels. lateral span.
  # Coordinates on the observation image frame the vehicle's POV is.
  veh_horz_pos_ratio: 0.5 # relative position from left (0) to right (1). Use 0.5 to center it.
  veh_vert_pos_ratio: 0.0 # relative position from bottom (0) to top (1). Use 0.5 to center it.

particle_filter:
  num_particles: 10 # Number of particles to track.
  state_size: 3 # Number of variables in the state. (i.e., (x,y,yaw)).
  random_sampling_rate: 0.1 # Proportion in range [0, 1] of population that will be sampled randomly instead of from the previous generation.

actions:
  use_discrete_actions: true # if true, only command 90deg pivots and short forward motions. if false, use continuous action space and command any 2D twist.
  discrete_forward_dist: 0.5 # meters forward to move for discrete motion action.
  discrete_forward_skip_probability: 0.1 # probability that a forward action will be skipped instead of commanded to the robot.

path_planning:
  do_path_planning: false # if true, use A* to compute a full path to the goal point, then use pure pursuit to choose a motion command. if false, navigate directly towards goal point.

# Configs for running simulator node for basic testing.
simulator:
  ground_truth_map:
    fname: "igvc1.png" # Name of the map image file to use. Image should be in cmn_pkg/config/maps/ directory.
    resolution: 0.01 # Map resolution in meters/pixel.
    occ_thresh: 200 # Integer in range [0,255]. All cells with grayscale value < this will be considered occupied.
    obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.
  ground_truth_pose:
    veh_x_initial: 0.0 # meters from left.
    veh_y_initial: 0.0 # meters from bottom.
    veh_yaw_initial: 0.0 # radians. 0 = facing right, increases CCW.
  allow_motion_through_occupied_cells: true # if true, robot is allowed to be in occluded cells.

constraints:
  fwd: 0.2 # commanded linear velocity must be between 0 and this amount (meters).
  ang: 0.1 #0.0546 # commanded angular velocity has its magnitude limited by this amount (radians).

test:
  run_debug_mode: false # Run the test mode, which will display images and print text that are normally skipped.
  save_data_for_training: false # Save measurements, true odom pose on map, and "observation" pulled from the map, all with timestamps & frame numbers to associate them. This data can be used to retrain the ML model, and also allows re-running the project to evaluate the model & localization to compare to ground truth. May also need to save commands or relative motions depending on how the localization is implemented. NOTE could use rosbags for the replaying aspect, but for training the model we still need a way to get associated measurements + "observations".
