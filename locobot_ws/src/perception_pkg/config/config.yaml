# Parameters for the project

# Rostopics used throughout the project.
topics:
  measurements: "/locobot/camera/color/image_raw"
  observations: "/observation"
  occ_map: "/map/occ"
  raw_map: "/map/raw"
  localization: "/state_est"
  commands: "/locobot/mobile_base/commands/velocity"

map:
  fname: "igvc1.png" # Name of the map image file to use. Image should be in perception_pkg/config/maps/ directory.
  resolution: 0.01 # Assumed map resolution, in meters/pixel. This will later be estimated as part of the filter to allow a map with unknown scale to be used.
  occ_thresh: 200 # Integer in range [0,255]. All cells with grayscale value < this will be considered occupied.
  obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.

# Config params defining how the observation output from the perception model relates to the robot.
# These should be known, since they are determined by the observation "ground truth" outputs used to train the model in the first place.
observation:
  resolution: 0.01 # Image resolution, in meters/pixel.
  height: 50 # in pixels. forward distance ahead of vehicle.
  width: 100 # in pixels. lateral span.
  # Coordinates on the observation image frame the vehicle's POV is. (origin is bottom center)
  # FOR NOW, CHANGING VEH POSE IS NOT SUPPORTED
  veh_horz_pos: 0 # px from center.
  veh_vert_pos: 0 # px from bottom. use 1/2 of height to put veh in center.
  veh_yaw: 0.0 # radians. 0 = facing right, increases CCW. 

perception_node_dt: 0.1 # timer period of perception_node's main update loop (seconds). NOTE later we can characterize the runtime of the model to optimize this value.

particle_filter:
  num_particles: 1000 # Number of particles to track.
  state_size: 3 # Number of variables in the state. (i.e., (x,y,yaw)).

# Configs for running simulator node for basic testing.
simulator:
  ground_truth_map:
    fname: "igvc1.png" # Name of the map image file to use. Image should be in perception_pkg/config/maps/ directory.
    resolution: 0.01 # Map resolution in meters/pixel.
    occ_thresh: 200 # Integer in range [0,255]. All cells with grayscale value < this will be considered occupied.
    obstacle_balloon_radius: 2 # Number of cells to expand all occupied cells by. Expansion happens in a square, treating diagonal and adjacent distances as equivalent.
  ground_truth_pose:
    veh_x_initial: 0.0 # meters from left.
    veh_y_initial: 0.0 # meters from bottom.
    veh_yaw_initial: 0.0 # radians. 0 = facing right, increases CCW.



test:
  run_debug_mode: false # Run the test mode, which will display images and print text that are normally skipped.
  save_data_for_training: false # Save measurements, true odom pose on map, and "observation" pulled from the map, all with timestamps & frame numbers to associate them. This data can be used to retrain the ML model, and also allows re-running the project to evaluate the model & localization to compare to ground truth. May also need to save commands or relative motions depending on how the localization is implemented. NOTE could use rosbags for the replaying aspect, but for training the model we still need a way to get associated measurements + "observations".
